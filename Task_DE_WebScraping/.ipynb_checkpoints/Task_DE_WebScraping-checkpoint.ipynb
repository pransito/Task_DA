{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'html5lib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-41319c2d88ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbs4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mhtml5lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0murljoin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'html5lib'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import html5lib\n",
    "import re\n",
    "from urllib.parse import urljoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base url\n",
    "# there are a bunch of \"makes\" (manufacturers) which are buttons\n",
    "# all associated with links to the catalogue\n",
    "# we need to get the name of the make and the link\n",
    "base = 'https://www.urparts.com/'\n",
    "extension = 'index.cfm/page/catalogue'\n",
    "\n",
    "def get_soup(cur_url):\n",
    "    s      = requests.session()\n",
    "    r      = s.get(cur_url)\n",
    "    soup   = BeautifulSoup(r.text,\"html5lib\")\n",
    "    return(soup)\n",
    "\n",
    "soup = get_soup(urljoin(base,extension))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "catalogue/\n",
      "https://www.urparts.com/\n",
      "doing the test now!!!!!!!\n",
      "catalogue/\n",
      "index.cfm/page/agri-home\n",
      "doing the test now!!!!!!!\n",
      "catalogue/\n",
      "index.cfm/page/choosesellertype\n",
      "doing the test now!!!!!!!\n",
      "catalogue/\n",
      "index.cfm/page/faqs\n",
      "doing the test now!!!!!!!\n",
      "catalogue/\n",
      "index.cfm/page/aboutus\n",
      "doing the test now!!!!!!!\n",
      "catalogue/\n",
      "index.cfm/page/kudos\n",
      "doing the test now!!!!!!!\n",
      "catalogue/\n",
      "index.cfm/page/login\n",
      "doing the test now!!!!!!!\n",
      "catalogue/\n",
      "index.cfm/page/catalogue/Ammann\n",
      "doing the test now!!!!!!!\n",
      "catalogue/\n",
      "index.cfm/page/catalogue/Atlas\n",
      "doing the test now!!!!!!!\n",
      "catalogue/\n",
      "index.cfm/page/catalogue/Atlas-Copco\n",
      "doing the test now!!!!!!!\n",
      "catalogue/\n",
      "index.cfm/page/catalogue/Bell\n",
      "doing the test now!!!!!!!\n",
      "catalogue/\n",
      "index.cfm/page/catalogue/Bomag\n",
      "doing the test now!!!!!!!\n",
      "catalogue/\n",
      "index.cfm/page/catalogue/Doosan\n",
      "doing the test now!!!!!!!\n",
      "catalogue/\n",
      "index.cfm/page/catalogue/FAI\n",
      "doing the test now!!!!!!!\n",
      "catalogue/\n",
      "index.cfm/page/catalogue/Hitachi\n",
      "doing the test now!!!!!!!\n",
      "catalogue/\n",
      "index.cfm/page/catalogue/Hyundai\n",
      "doing the test now!!!!!!!\n",
      "catalogue/\n",
      "index.cfm/page/catalogue/Isuzu\n",
      "doing the test now!!!!!!!\n",
      "catalogue/\n",
      "index.cfm/page/catalogue/JCB\n",
      "doing the test now!!!!!!!\n",
      "catalogue/\n",
      "index.cfm/page/catalogue/Kawasaki\n",
      "doing the test now!!!!!!!\n",
      "catalogue/\n",
      "index.cfm/page/catalogue/Komatsu\n",
      "doing the test now!!!!!!!\n",
      "catalogue/\n",
      "index.cfm/page/catalogue/Mitsubishi\n",
      "doing the test now!!!!!!!\n",
      "catalogue/\n",
      "index.cfm/page/catalogue/Moxy\n",
      "doing the test now!!!!!!!\n",
      "catalogue/\n",
      "index.cfm/page/catalogue/Volvo\n",
      "doing the test now!!!!!!!\n",
      "catalogue/\n",
      "index.cfm/page/sitemap\n",
      "doing the test now!!!!!!!\n",
      "catalogue/\n",
      "index.cfm/page/termsofuse\n",
      "doing the test now!!!!!!!\n",
      "catalogue/\n",
      "http://blog.urparts.com\n",
      "doing the test now!!!!!!!\n",
      "catalogue/\n",
      "index.cfm/page/enquiries\n",
      "doing the test now!!!!!!!\n",
      "catalogue/\n",
      "index.cfm/page/contactus\n",
      "doing the test now!!!!!!!\n",
      "catalogue/\n",
      "index.cfm/page/archivedenquiries\n",
      "doing the test now!!!!!!!\n",
      "catalogue/\n",
      "index.cfm/page/catalogue\n",
      "doing the test now!!!!!!!\n",
      "catalogue/\n",
      "https://twitter.com/#!/urparts\n",
      "doing the test now!!!!!!!\n",
      "catalogue/\n",
      "http://www.facebook.com/pages/Urpartscom/191353087561078\n",
      "doing the test now!!!!!!!\n",
      "catalogue/\n",
      "https://www.linkedin.com/company/urparts-com/\n",
      "doing the test now!!!!!!!\n",
      "catalogue/\n",
      "https://www.youtube.com/channel/UC1GD-kw69jhItZ2_-EXvTRA\n",
      "doing the test now!!!!!!!\n",
      "{('Ammann',): 'index.cfm/page/catalogue/Ammann', ('Atlas',): 'index.cfm/page/catalogue/Atlas', ('Atlas-Copco',): 'index.cfm/page/catalogue/Atlas-Copco', ('Bell',): 'index.cfm/page/catalogue/Bell', ('Bomag',): 'index.cfm/page/catalogue/Bomag', ('Doosan',): 'index.cfm/page/catalogue/Doosan', ('FAI',): 'index.cfm/page/catalogue/FAI', ('Hitachi',): 'index.cfm/page/catalogue/Hitachi', ('Hyundai',): 'index.cfm/page/catalogue/Hyundai', ('Isuzu',): 'index.cfm/page/catalogue/Isuzu', ('JCB',): 'index.cfm/page/catalogue/JCB', ('Kawasaki',): 'index.cfm/page/catalogue/Kawasaki', ('Komatsu',): 'index.cfm/page/catalogue/Komatsu', ('Mitsubishi',): 'index.cfm/page/catalogue/Mitsubishi', ('Moxy',): 'index.cfm/page/catalogue/Moxy', ('Volvo',): 'index.cfm/page/catalogue/Volvo'}\n"
     ]
    }
   ],
   "source": [
    "def get_links(soup,link_string):\n",
    "    links = soup.find_all(\"li\")\n",
    "    links_dict = {}\n",
    "    for l in links:\n",
    "        if l.find('a') is not None:\n",
    "            cur_text = l.get_text().strip()\n",
    "            cur_url  = l.a['href']\n",
    "            \n",
    "            # link_string is a tuple\n",
    "            critical_string = '/'.join(link_string)\n",
    "            critical_string = critical_string + '/'\n",
    "            #print(critical_string)\n",
    "            \n",
    "            # make the key for the dictionary\n",
    "            str_list = list(link_string)\n",
    "            str_list.append(cur_text)\n",
    "            new_key = tuple(str_list[1:])\n",
    "            \n",
    "            #print(cur_url)\n",
    "            #print('doing the test now!!!!!!!')\n",
    "            if cur_url.find(critical_string) is not -1:\n",
    "                links_dict[new_key] = cur_url\n",
    "    return(links_dict)\n",
    "\n",
    "manufacturers = get_links(soup,link_string=tuple(['catalogue']))\n",
    "print(manufacturers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next level: category [parts catalogue]\n",
    "category_by_manuf = {}\n",
    "for m in list(manufacturers.keys()):\n",
    "    cur_url = urljoin(base,manufacturers[m])\n",
    "    s = requests.session()\n",
    "    r = s.get(cur_url)\n",
    "    soup = BeautifulSoup(r.text,\"html5lib\")\n",
    "    categories = get_links(soup,link_string='catalogue/' + m)\n",
    "    category_by_manuf[m] = categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roller Parts\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot mix str and non-str arguments",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-78-8975d43281d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;31m# category in manufactuerer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mcur_url\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murljoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcategory_by_manuf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcur_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Miniconda3\\lib\\urllib\\parse.py\u001b[0m in \u001b[0;36murljoin\u001b[1;34m(base, url, allow_fragments)\u001b[0m\n\u001b[0;32m    485\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 487\u001b[1;33m     \u001b[0mbase\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_coerce_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_coerce_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    488\u001b[0m     \u001b[0mbscheme\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbnetloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbfragment\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m             \u001b[0murlparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_fragments\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Miniconda3\\lib\\urllib\\parse.py\u001b[0m in \u001b[0;36m_coerce_args\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;31m# \"scheme=''\" default argument to some functions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mstr_input\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cannot mix str and non-str arguments\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mstr_input\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0margs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0m_noop\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot mix str and non-str arguments"
     ]
    }
   ],
   "source": [
    "# next level model\n",
    "parts_by_category_by_manuf = {}\n",
    "for m in list(category_by_manuf.keys()):\n",
    "    # manufacturer\n",
    "    for c in category_by_manuf[m]:\n",
    "        #print(c)\n",
    "        # category in manufactuerer\n",
    "        cur_url = urljoin(base,category_by_manuf[m])\n",
    "        s = requests.session()\n",
    "        r = s.get(cur_url)\n",
    "        soup = BeautifulSoup(r.text,\"html5lib\")\n",
    "        parts = get_links(soup,link_string='catalogue/' + m + '/' + c)\n",
    "        parts_by_category_by_manuf[(m,c)] = parts\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.urparts.com/\n",
      "{'Roller Parts': 'index.cfm/page/catalogue/Ammann/Roller Parts'}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot mix str and non-str arguments",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-81-3cfb420a0fed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcategory_by_manuf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0murljoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcategory_by_manuf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\Miniconda3\\lib\\urllib\\parse.py\u001b[0m in \u001b[0;36murljoin\u001b[1;34m(base, url, allow_fragments)\u001b[0m\n\u001b[0;32m    485\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 487\u001b[1;33m     \u001b[0mbase\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_coerce_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_coerce_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    488\u001b[0m     \u001b[0mbscheme\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbnetloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbfragment\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m             \u001b[0murlparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_fragments\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Miniconda3\\lib\\urllib\\parse.py\u001b[0m in \u001b[0;36m_coerce_args\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;31m# \"scheme=''\" default argument to some functions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mstr_input\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cannot mix str and non-str arguments\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mstr_input\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0margs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0m_noop\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot mix str and non-str arguments"
     ]
    }
   ],
   "source": [
    "print(base)\n",
    "print(category_by_manuf[m])\n",
    "urljoin(base,category_by_manuf[m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start over: we need a function that builds a soup\n",
    "# and then digs into the links that fullfill a certain criterion\n",
    "# the condition will be growing starting with 'catalogue'\n",
    "# and the subsequent names of the links\n",
    "\n",
    "# the function can take as input a base-link (start of recursion)\n",
    "# or a dictionary to dig into\n",
    "base = 'https://www.urparts.com/'\n",
    "extension = 'index.cfm/page/catalogue'\n",
    "\n",
    "def scrape(base=None, scrape_dict=None,extension=extension,condition_seed='catalogue'):\n",
    "    if base is None and scrape_dict is None:\n",
    "        raise ValueError('Neither base_link nor scrape_dict provided')\n",
    "        \n",
    "    if base is None:\n",
    "        raise ValueError('Base_link needs to be always provided')\n",
    "    \n",
    "    if scrape_dict is None:\n",
    "        #print('create scrape_dict')\n",
    "        # initialization\n",
    "        cur_url = urljoin(base,extension)\n",
    "        soup = get_soup(cur_url)\n",
    "        scrape_dict = get_links(soup,link_string=tuple([condition_seed]))\n",
    "        #print(scrape_dict)\n",
    "        \n",
    "    new_dict = {}\n",
    "    # how often to call the function and create a deeper dictionary\n",
    "    for s in list(scrape_dict.keys()):\n",
    "        #print('now in for loop')\n",
    "        cur_url = urljoin(base,scrape_dict[s])\n",
    "        #print(cur_url)\n",
    "        soup = get_soup(cur_url)\n",
    "        \n",
    "        # build the link_string tuple\n",
    "        critical_string = [condition_seed]\n",
    "        add_string = list(s)\n",
    "        critical_string = tuple(critical_string + add_string)\n",
    "        #print(critical_string)\n",
    "        cur_dict = get_links(soup,link_string=critical_string)\n",
    "        #print(cur_dict)\n",
    "        \n",
    "        new_dict.update(cur_dict)\n",
    "            \n",
    "    return(new_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dict = scrape(base=base, scrape_dict=None,extension=extension,condition_seed='catalogue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('Ammann', 'Roller Parts'): 'index.cfm/page/catalogue/Ammann/Roller Parts', ('Atlas', 'Excavator Parts'): 'index.cfm/page/catalogue/Atlas/Excavator Parts', ('Atlas-Copco', 'Other Parts'): 'index.cfm/page/catalogue/Atlas-Copco/Other Parts', ('Bell', 'Backhoe Parts'): 'index.cfm/page/catalogue/Bell/Backhoe Parts', ('Bell', 'Grader Parts'): 'index.cfm/page/catalogue/Bell/Grader Parts', ('Bell', 'Loader Parts'): 'index.cfm/page/catalogue/Bell/Loader Parts', ('Bell', 'Off Road Truck Parts'): 'index.cfm/page/catalogue/Bell/Off Road Truck Parts', ('Bomag', 'Roller Parts'): 'index.cfm/page/catalogue/Bomag/Roller Parts', ('Doosan', 'Excavator Parts'): 'index.cfm/page/catalogue/Doosan/Excavator Parts', ('Doosan', 'Loader Parts'): 'index.cfm/page/catalogue/Doosan/Loader Parts', ('FAI', 'Excavator Parts'): 'index.cfm/page/catalogue/FAI/Excavator Parts', ('Hitachi', 'Backhoe Parts'): 'index.cfm/page/catalogue/Hitachi/Backhoe Parts', ('Hitachi', 'Crane Parts'): 'index.cfm/page/catalogue/Hitachi/Crane Parts', ('Hitachi', 'Dozers and Crawler Loader Parts'): 'index.cfm/page/catalogue/Hitachi/Dozers and Crawler Loader Parts', ('Hitachi', 'Excavator Parts'): 'index.cfm/page/catalogue/Hitachi/Excavator Parts', ('Hitachi', 'Road Truck Parts'): 'index.cfm/page/catalogue/Hitachi/Road Truck Parts', ('Hyundai', 'Crane Parts'): 'index.cfm/page/catalogue/Hyundai/Crane Parts', ('Hyundai', 'Dozers and Crawler Loader Parts'): 'index.cfm/page/catalogue/Hyundai/Dozers and Crawler Loader Parts', ('Hyundai', 'Excavator Parts'): 'index.cfm/page/catalogue/Hyundai/Excavator Parts', ('Hyundai', 'Forklift Parts'): 'index.cfm/page/catalogue/Hyundai/Forklift Parts', ('Hyundai', 'Loader Parts'): 'index.cfm/page/catalogue/Hyundai/Loader Parts', ('Isuzu', 'Engines & Engine Parts'): 'index.cfm/page/catalogue/Isuzu/Engines & Engine Parts', ('JCB', 'Backhoe Parts'): 'index.cfm/page/catalogue/JCB/Backhoe Parts', ('JCB', 'Engines & Engine Parts'): 'index.cfm/page/catalogue/JCB/Engines & Engine Parts', ('JCB', 'Excavator Parts'): 'index.cfm/page/catalogue/JCB/Excavator Parts', ('JCB', 'Loader Parts'): 'index.cfm/page/catalogue/JCB/Loader Parts', ('JCB', 'Off Road Truck Parts'): 'index.cfm/page/catalogue/JCB/Off Road Truck Parts', ('Kawasaki', 'Loader Parts'): 'index.cfm/page/catalogue/Kawasaki/Loader Parts', ('Komatsu', 'Backhoe Parts'): 'index.cfm/page/catalogue/Komatsu/Backhoe Parts', ('Komatsu', 'Crane Parts'): 'index.cfm/page/catalogue/Komatsu/Crane Parts', ('Komatsu', 'Dozers and Crawler Loader Parts'): 'index.cfm/page/catalogue/Komatsu/Dozers and Crawler Loader Parts', ('Komatsu', 'Excavator Parts'): 'index.cfm/page/catalogue/Komatsu/Excavator Parts', ('Komatsu', 'Grader Parts'): 'index.cfm/page/catalogue/Komatsu/Grader Parts', ('Komatsu', 'Loader Parts'): 'index.cfm/page/catalogue/Komatsu/Loader Parts', ('Mitsubishi', 'Engines & Engine Parts'): 'index.cfm/page/catalogue/Mitsubishi/Engines & Engine Parts', ('Moxy', 'Off Road Truck Parts'): 'index.cfm/page/catalogue/Moxy/Off Road Truck Parts', ('Volvo', 'Backhoe Parts'): 'index.cfm/page/catalogue/Volvo/Backhoe Parts', ('Volvo', 'Excavator Parts'): 'index.cfm/page/catalogue/Volvo/Excavator Parts', ('Volvo', 'Grader Parts'): 'index.cfm/page/catalogue/Volvo/Grader Parts', ('Volvo', 'Loader Parts'): 'index.cfm/page/catalogue/Volvo/Loader Parts', ('Volvo', 'Off Road Truck Parts'): 'index.cfm/page/catalogue/Volvo/Off Road Truck Parts', ('Volvo', 'Roller Parts'): 'index.cfm/page/catalogue/Volvo/Roller Parts'}\n"
     ]
    }
   ],
   "source": [
    "print(new_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scrape' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a24084be62f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_dict2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscrape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscrape_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mextension\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextension\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcondition_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'catalogue'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# doing it another time... and another time... takes a long time; maybe put into a different?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scrape' is not defined"
     ]
    }
   ],
   "source": [
    "new_dict2 = scrape(base=base, scrape_dict=new_dict,extension=extension,condition_seed='catalogue')\n",
    "# doing it another time... and another time... takes a long time; maybe put into a different?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_string=('catalogue', 'Ammann')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('catalogue', 'Ammann')]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "sequence item 0: expected str instance, tuple found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-190-12b4de21dc2f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcritical_string\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlink_string\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcritical_string\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcritical_string\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'/'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcritical_string\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: sequence item 0: expected str instance, tuple found"
     ]
    }
   ],
   "source": [
    "critical_string = [link_string]\n",
    "#print(critical_string)\n",
    "critical_string = '/'.join(critical_string)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
